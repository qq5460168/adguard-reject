#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠŸèƒ½ï¼šè¯»å– rules.txt ä¸­çš„ QuantumultX åœ¨çº¿è§„åˆ™ URL â†’ æ‰¹é‡æ‹‰å–è§„åˆ™ â†’ åˆå¹¶å¹¶è½¬æ¢ä¸º AdGuard / hosts è§„åˆ™
æ”¹è¿›ç‚¹ï¼š
- æŒ‰ç”¨æˆ·è¦æ±‚ï¼š
  - host, åŸŸå, reject  -> è½¬ä¸º hosts æ ¼å¼: "0.0.0.0 åŸŸå"
  - host-suffix, åŸŸå, reject -> è½¬ä¸º AdGuard URL æ ¼å¼: "||åŸŸå^"
  - host-keyword, å…³é”®è¯, reject -> è½¬ä¸º AdGuard URL æ ¼å¼: "||å…³é”®è¯^"
- æ›´å¥å£®çš„æ­£åˆ™ï¼Œæ”¯æŒæ›´å®½æ¾çš„åŸŸå/keyword æ•è·ï¼ˆåŒ…æ‹¬ç‚¹å’Œ Unicodeï¼‰
- å»é™¤é‡å¤ï¼Œä¿ç•™æ³¨é‡Šè¡Œå¹¶åœ¨è¾“å‡ºä¸­æ ‡æ³¨æœªè¯†åˆ«è§„åˆ™
- æ›´å‹å¥½çš„é”™è¯¯å¤„ç†ä¸ç»Ÿè®¡ä¿¡æ¯
"""
from typing import List
import re
import requests
import sys
import os

# é…ç½®
URL_CONFIG_FILE = "rules.txt"
ADGUARD_OUTPUT_FILE = "adguard-rules.txt"
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
REQUEST_TIMEOUT = 30

# é€šç”¨ç”¨äºæ•è·åŸŸå / å…³é”®è¯çš„æ¨¡å¼ï¼šå°½é‡å®½æ¾ï¼Œæ•è·éé€—å·éç©ºç™½ä¸²ï¼ˆåŒ…æ‹¬å¸¦ç‚¹çš„åŸŸåæˆ–å…³é”®è¯ï¼‰
TOKEN_RE = r'([^\s,]+)'


def read_rule_urls(config_file: str) -> List[str]:
    """è¯»å– rules.txt ä¸­çš„æ‰€æœ‰ URLï¼Œè¿”å›å»é‡åçš„ URL åˆ—è¡¨ï¼ˆå¿½ç•¥ç©ºè¡Œå’Œ # æ³¨é‡Šï¼‰"""
    if not os.path.exists(config_file):
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ {config_file}")
        sys.exit(1)

    with open(config_file, 'r', encoding='utf-8') as f:
        lines = [line.rstrip('\n') for line in f]

    urls = []
    seen = set()
    for line in lines:
        s = line.strip()
        if not s or s.startswith('#'):
            continue
        if s not in seen:
            seen.add(s)
            urls.append(s)

    if not urls:
        print(f"âŒ é”™è¯¯ï¼š{config_file} ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆ URL")
        sys.exit(1)

    print(f"ğŸ“‹ ä» {config_file} è¯»å–åˆ° {len(urls)} æ¡è§„åˆ™æºï¼š")
    for i, u in enumerate(urls, 1):
        print(f"  {i}. {u}")
    return urls


def fetch_single_url_rules(url: str) -> List[str]:
    """æ‹‰å–å•ä¸ª URL çš„è§„åˆ™æ–‡æœ¬å¹¶æŒ‰è¡Œè¿”å›ï¼ˆè¿‡æ»¤ç©ºè¡Œï¼‰"""
    try:
        print(f"\nğŸ“¥ æ­£åœ¨æ‹‰å–ï¼š{url}")
        r = requests.get(url, timeout=REQUEST_TIMEOUT, headers={"User-Agent": USER_AGENT}, allow_redirects=True)
        r.raise_for_status()
        text = r.content.decode('utf-8-sig', errors='ignore')
        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
        print(f"âœ… æ‹‰å–æˆåŠŸï¼š{len(lines)} è¡Œæœ‰æ•ˆè§„åˆ™")
        return lines
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸  æ‹‰å–å¤±è´¥ï¼š{url} -> {e}")
        return []


def convert_rule_line(line: str):
    """
    å°†å•è¡Œ QuantumultX è§„åˆ™è½¬æ¢ä¸ºç›®æ ‡è§„åˆ™ã€‚
    è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆè½¬æ¢åçš„è§„åˆ™ï¼‰æˆ– Noneï¼ˆæœªè¯†åˆ«æˆ–ä¸éœ€è¦è½¬æ¢ï¼‰ã€‚
    è½¬æ¢è§„åˆ™ï¼ˆæŒ‰ç”¨æˆ·è¦æ±‚ï¼‰ï¼š
      - host, åŸŸå, reject -> "0.0.0.0 åŸŸå"
      - host-suffix, åŸŸååç¼€, reject -> "||åŸŸå^"
      - host-keyword, å…³é”®è¯, reject -> "||å…³é”®è¯^"
      - url, åè®®://åŸŸå/è·¯å¾„, reject -> "||åŸŸå/è·¯å¾„^"ï¼ˆä¿ç•™è·¯å¾„ä»¥æé«˜ç²¾ç¡®åº¦ï¼‰
    å…¶å®ƒï¼šæ³¨é‡Šè¡Œç”±è°ƒç”¨è€…ç›´æ¥ä¿ç•™ï¼Œæœªè¯†åˆ«åˆ™è¿”å› Noneã€‚
    """
    s = line.strip()

    # host,domain,reject  -> hosts
    m = re.match(rf'host\s*,\s*{TOKEN_RE}\s*,\s*reject\s*$', s, re.I)
    if m:
        domain = m.group(1)
        # é¿å…æŠŠé€šé…ç¬¦ç­‰å¥‡æ€ªå­—ç¬¦ä¸²å†™å…¥ hosts
        if domain in ('*', ''):
            return None
        return f"0.0.0.0 {domain}"

    # host-suffix,domain, reject -> ||domain^
    m = re.match(rf'host-suffix\s*,\s*{TOKEN_RE}\s*,\s*reject\s*$', s, re.I)
    if m:
        suffix = m.group(1)
        # å½“åç¼€ä»¥ç‚¹å¼€å¤´æˆ–åŒ…å«é€šé…ç¬¦æ—¶ï¼Œä»æŒ‰ ||suffix^ å¤„ç†ï¼ˆAdGuard å¯ä»¥å¤„ç†å¸¸è§åç¼€ï¼‰
        return f"||{suffix}^"

    # host-keyword,keyword, reject -> ||keyword^
    m = re.match(rf'host-keyword\s*,\s*{TOKEN_RE}\s*,\s*reject\s*$', s, re.I)
    if m:
        keyword = m.group(1)
        # å°†å…³é”®è¯ç›´æ¥è½¬æ¢ä¸ºåŒ…å«å‰ç¼€åŒ¹é…çš„ AdGuard å½¢å¼
        # æ³¨æ„ï¼šhost-keyword æœ‰æ—¶ä¸ºåŸŸåçš„éƒ¨åˆ†ï¼Œè½¬æ¢ä¸º ||keyword^ èƒ½åŒ¹é…ä»¥è¯¥å…³é”®è¯å¼€å¤´çš„ä¸»æœºæˆ–åŸŸå
        return f"||{keyword}^"

    # url,protocol://domain/... , reject  -> ||domain/path^  ï¼ˆä¿ç•™è·¯å¾„ï¼‰
    # åŒæ—¶æ”¯æŒæ²¡æœ‰åè®®çš„ url,domain/path çš„æƒ…å½¢
    m = re.match(rf'url\s*,\s*(?:((?:https?|wss?)://)?)([^\s\/,]+)(/[^\s,]*)?\s*,\s*reject\s*$', s, re.I)
    if m:
        domain = m.group(2)
        path = m.group(3) or ""
        # å¯¹è·¯å¾„è¿›è¡Œä¿æŠ¤ï¼šAdGuard çš„ ^ è¡¨ç¤ºåˆ†ç•Œç¬¦ï¼Œå¯ä»¥ç›´æ¥æ‹¼æ¥
        return f"||{domain}{path}^"

    # å…¶ä»– reject å½¢å¼ï¼šæ¯”å¦‚ plain 'reject' æˆ– regex ç­‰ï¼Œæš‚ä¸å¤„ç†
    return None


def merge_and_convert(all_rules: List[str], output_file: str) -> None:
    """åˆå¹¶æ‰€æœ‰è§„åˆ™å¹¶è½¬æ¢å†™å…¥è¾“å‡ºæ–‡ä»¶"""
    header = [
        "# ===============================",
        "# è‡ªåŠ¨æ‹‰å–+åˆå¹¶+è½¬æ¢è‡ª QuantumultX åœ¨çº¿è§„åˆ™",
        f"# è§„åˆ™æ¥æºé…ç½®ï¼š{URL_CONFIG_FILE}",
        "# æ”¯æŒè§„åˆ™ç±»å‹ï¼ˆå·²å®ç°è½¬æ¢ï¼‰ï¼š",
        "#  - host, åŸŸå, reject  -> hosts: 0.0.0.0 åŸŸå",
        "#  - host-suffix, åŸŸååç¼€, reject -> AdGuard: ||åŸŸå^",
        "#  - host-keyword, å…³é”®è¯, reject -> AdGuard: ||å…³é”®è¯^",
        "#  - url, åè®®://åŸŸå/è·¯å¾„, reject -> AdGuard: ||åŸŸå/è·¯å¾„^",
        "# æ³¨ï¼šä¿ç•™åŸæ³¨é‡Šè¡Œï¼›æœªè¯†åˆ«çš„è§„åˆ™ä¼šä»¥æ³¨é‡Šå½¢å¼å†™å‡ºä»¥ä¾¿äººå·¥æ£€æŸ¥",
        "# ===============================\n"
    ]

    out_lines = []
    out_lines.extend(header)
    converted = set()
    converted_count = 0
    unrecognized_count = 0
    raw_count = len(all_rules)

    for line in all_rules:
        if not line:
            continue
        stripped = line.strip()

        # ä¿ç•™æ³¨é‡Šè¡ŒåŸæ ·ï¼ˆä½†ä¸è®¡å…¥å»é‡ï¼‰
        if stripped.startswith('#'):
            out_lines.append(stripped)
            continue

        # åªå¤„ç†åŒ…å« reject çš„è§„åˆ™ï¼ˆQuantumultX é‡Œé€šå¸¸æ˜¯ ... ,rejectï¼‰
        # å¦‚æœæœ‰ reject å‡ºç°åœ¨è¡Œä¸­æ‰å°è¯•è½¬æ¢
        if 'reject' not in stripped.lower():
            # è·³è¿‡ä¸å« reject çš„è§„åˆ™ï¼ˆä¹Ÿå¯æŒ‰éœ€æ±‚ä¿ç•™ï¼‰
            out_lines.append(f"# è·³è¿‡é reject è§„åˆ™ï¼š{stripped}")
            continue

        converted_rule = convert_rule_line(stripped)
        if converted_rule:
            if converted_rule not in converted:
                out_lines.append(converted_rule)
                converted.add(converted_rule)
                converted_count += 1
            else:
                # å·²å­˜åœ¨åˆ™è·³è¿‡ï¼ˆå»é‡ï¼‰
                continue
        else:
            # æœªè¯†åˆ«ï¼Œå†™ä¸ºæ³¨é‡Šä»¥ä¾¿åç»­äººå·¥æ£€æŸ¥
            out_lines.append(f"# æœªè¯†åˆ«è§„åˆ™ï¼š{stripped}")
            unrecognized_count += 1

    # å†™å…¥æ–‡ä»¶
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(out_lines))
    except OSError as e:
        print(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥ï¼š{output_file} -> {e}")
        sys.exit(1)

    # ç»Ÿè®¡è¾“å‡º
    print("\nâœ… è½¬æ¢å®Œæˆ")
    print(f"  - åŸå§‹è§„åˆ™è¡Œæ•°ï¼š{raw_count}")
    print(f"  - æˆåŠŸè½¬æ¢ï¼ˆå»é‡åï¼‰è§„åˆ™æ•°ï¼š{converted_count}")
    print(f"  - æœªè¯†åˆ«è§„åˆ™æ•°ï¼ˆå·²å†™ä¸ºæ³¨é‡Šï¼‰ï¼š{unrecognized_count}")
    print(f"  - è¾“å‡ºæ–‡ä»¶ï¼š{output_file}")


def main():
    urls = read_rule_urls(URL_CONFIG_FILE)
    all_rules: List[str] = []
    for url in urls:
        lines = fetch_single_url_rules(url)
        if lines:
            all_rules.extend(lines)
            print(f"  â†’ å½“å‰ç´¯è®¡è§„åˆ™è¡Œæ•°ï¼š{len(all_rules)}")

    if not all_rules:
        print("âŒ é”™è¯¯ï¼šæœªæ‹‰å–åˆ°ä»»ä½•è§„åˆ™ï¼Œé€€å‡ºã€‚")
        sys.exit(1)

    merge_and_convert(all_rules, ADGUARD_OUTPUT_FILE)


if __name__ == "__main__":
    main()
